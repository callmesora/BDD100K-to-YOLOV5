{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58ff0729",
   "metadata": {},
   "source": [
    "# Convert BDD100K To YOLOV5 PyTorch / Scaled YOLOV4 / YOLOV4 /YOLOX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78aa5ae5",
   "metadata": {},
   "source": [
    "The Berkeley Deep Drive (BDD) dataset is one of the largest and most\n",
    "diverse video datasets for autonomous vehicles.\n",
    "\n",
    "The BDD100K dataset contains 100,000 video clips collected from more than\n",
    "50,000 rides covering New York, San Francisco Bay Area, and other regions.\n",
    "The dataset contains diverse scene types such as city streets, residential\n",
    "areas, and highways. Furthermore, the videos were recorded in diverse\n",
    "weather conditions at different times of the day.\n",
    "\n",
    "The videos are split into training (70K), validation (10K) and testing\n",
    "(20K) sets. Each video is 40 seconds long with 720p resolution and a frame\n",
    "rate of 30fps. The frame at the 10th second of each video is annotated for\n",
    "image classification, detection, and segmentation tasks.\n",
    "\n",
    "In order to load the BDD100K dataset, you must download the source data\n",
    "manually. The directory should be organized in the following format::\n",
    "\n",
    "    source_dir/\n",
    "        labels/\n",
    "            bdd100k_labels_images_train.json\n",
    "            bdd100k_labels_images_val.json\n",
    "        images/\n",
    "            100k/\n",
    "                train/\n",
    "                test/\n",
    "                val/\n",
    "\n",
    "You can register at https://bdd-data.berkeley.edu in order to get links to\n",
    "download the data.\n",
    "\n",
    "Example usage::\n",
    "\n",
    "    import fiftyone as fo\n",
    "    import fiftyone.zoo as foz\n",
    "\n",
    "    # The path to the source files that you manually downloaded\n",
    "    source_dir = \"/path/to/dir-with-bdd100k-files\"\n",
    "\n",
    "    dataset = foz.load_zoo_dataset(\n",
    "        \"bdd100k\",\n",
    "        split=\"validation\",\n",
    "        source_dir=source_dir,\n",
    "    )\n",
    "\n",
    "    session = fo.launch_app(dataset)\n",
    "\n",
    "Dataset size\n",
    "    7.10 GB\n",
    "\n",
    "Source\n",
    "    https://bdd-data.berkeley.edu\n",
    "\n",
    "Args:\n",
    "    source_dir (None): the directory containing the manually downloaded\n",
    "        BDD100K files\n",
    "    copy_files (True): whether to move (False) or create copies (True) of\n",
    "        the source files when populating the dataset directory\n",
    "\n",
    "***** Tags *****\n",
    "image, multilabel, automotive, manual\n",
    "\n",
    "***** Supported splits *****\n",
    "train, validation, test\n",
    "\n",
    "***** Dataset location *****\n",
    "Dataset 'bdd100k' is not downloaded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147f7a54",
   "metadata": {},
   "source": [
    "## New Labels or Old Labels?\n",
    "\n",
    "BDD100K had an update on the labels, feel free to use whatever but leave the file folder structure the Same"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d46ec0a",
   "metadata": {},
   "source": [
    "## First step Import and Analyse the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f52d9756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 'validation' already prepared\n",
      "Loading existing dataset 'bdd100k-validation'. To reload from disk, either delete the existing dataset or provide a custom `dataset_name` to use\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:5151/?notebook=true&handleId=515db2fa-da6d-4d76-a0c8-7c13a5d8d025\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f0427f034f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "\n",
    "# The path to the source files that you manually downloaded\n",
    "source_dir = \"bdd100k/\"\n",
    "\n",
    "dataset = foz.load_zoo_dataset(\n",
    "    \"bdd100k\",\n",
    "    split=\"validation\",\n",
    "    source_dir=source_dir,\n",
    "    copy_files=False,\n",
    ")\n",
    "\n",
    "session = fo.launch_app(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82e87e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!fiftyone zoo datasets info bdd100k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fa1af2",
   "metadata": {},
   "source": [
    "## Choose and Export dataset type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9befac2",
   "metadata": {},
   "source": [
    "Uncomment the fo.type that you want to conver to: \n",
    "\n",
    "YOLOV5 - YOLOv5Dataset\n",
    "Scaled YOLOV4 - YOLOv5Dataset\n",
    "\n",
    "YOLOV4 - YOLOv4Dataset\n",
    "YOLOX - VOCDetectionDataset or COCODetectionDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22f0f8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |█████████████| 70000/70000 [16.3m elapsed, 0s remaining, 72.5 samples/s]       \n"
     ]
    }
   ],
   "source": [
    "import fiftyone as fo\n",
    "\n",
    "# The Dataset or DatasetView containing the samples you wish to export\n",
    "dataset_or_view = dataset\n",
    "\n",
    "# The directory to which to write the exported dataset\n",
    "export_dir = \"bdd_in_YOLOV5_train_newLabels/\"\n",
    "\n",
    "\n",
    "# The type of dataset to export\n",
    "# Any subclass of `fiftyone.types.Dataset` is supported\n",
    "\n",
    "#Uncomment what ever format you wish to conver to\n",
    "\n",
    "#YOLOV5\n",
    "dataset_type = fo.types.YOLOv5Dataset  # for example\n",
    "\n",
    "\n",
    "# Export the dataset\n",
    "dataset_or_view.export(\n",
    "    export_dir=export_dir,\n",
    "    dataset_type=dataset_type\n",
    "    #export_media=\"copy\",\n",
    "    #label_field=label_field,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
